{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d902719c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook walks through the full analysis pipeline for exploring career patterns and predicting Cambridge attendance among data professionals. It is organized into sections with narrative explanations and code cells you can run interactively.\n",
    "\n",
    "Sections:\n",
    "\n",
    "1. Setup: imports and configuration\n",
    "\n",
    "2. Data \n",
    "\n",
    "3. Feature engineering (including fuzzy skill grouping)\n",
    "\n",
    "4. Exploratory skill analysis (Chi-square, plots)\n",
    "\n",
    "5. Model pipelines (Logistic, RF, ET, XGBoost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25320225",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0cd8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rapidfuzz import process, fuzz\n",
    "import ast\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cdbc44",
   "metadata": {},
   "source": [
    "## 2. Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf4d86",
   "metadata": {},
   "source": [
    "### 2.1 Data loading\n",
    "\n",
    "First, we load the raw anonymised admissions dataset exported from the LinkedIn scraping pipeline. This single file contains all profiles, universities, skills, and experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837ecf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../datasets/anonymised admissions dataset\")\n",
    "\n",
    "# Expect ~656 entries with columns: school_1, school_2, skills, experiences, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e4bf30",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing: separate Cambridge vs non-Cambridge profiles\n",
    "\n",
    "Creating a column to capture whether they have studied at the University of Cambridge.\n",
    "\n",
    "Creating a column to record other universities attended.\n",
    "\n",
    "To do this, we start by filtering out for only records where either school_1 or school_2 contain \"Cambridge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94aac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries missing both school_1 and school_2\n",
    "df1 = df.dropna(subset=['school_1','school_2']).copy()\n",
    "\n",
    "# Identify Cambridge profiles\n",
    "df2 = df1[df1['school_1'].str.contains('Cambridge', case=False, na=False) |\n",
    "          df1['school_2'].str.contains('Cambridge', case=False, na=False)].copy()\n",
    "\n",
    "df2['Cambridge?'] = 1\n",
    "\n",
    "df2['non-Cambridge uni'] = np.where(\n",
    "    df2['school_1'].str.contains('Cambridge', case=False, na=False),\n",
    "    df2['school_2'], df2['school_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f17f4",
   "metadata": {},
   "source": [
    "### 2.3 Building two datasets\n",
    "\n",
    "We now repeat the process for records that do not contain \"Cambridge.\"\n",
    "\n",
    "Since both school records include two different university fields, we have two approaches for creating the dataset:\n",
    "\n",
    "1. Duplication Method (dup_df): Data from two schools per profile was split into separate rows, increasing diversity but introducing some synthetic noise.\n",
    "\n",
    "2. Arbitrary Method (arb_df): Only one school (typically the most recent) was selected, ensuring greater reliability at the expense of some nuance.\n",
    "\n",
    "For this project, both datasets were generated, and similar models were run on each to better explore the nuances within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e4900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiles without Cambridge\n",
    "df3 = df1.loc[~df1.index.isin(df2.index)].copy()\n",
    "\n",
    "# Duplication method: split each row into two by school_1 and school_2\n",
    "rows = []\n",
    "for _, row in df3.iterrows():\n",
    "    for school in [row['school_1'], row['school_2']]:\n",
    "        new = row.copy()\n",
    "        new['school_1'] = school\n",
    "        new['non-Cambridge uni'] = school\n",
    "        rows.append(new)\n",
    "dup_df = pd.DataFrame(rows)\n",
    "dup_df['Cambridge?'] = 0\n",
    "\n",
    "dup_df = pd.concat([dup_df, df2], ignore_index=True)\n",
    "\n",
    "\n",
    "# Arbitrary method: one row per profile (take school_1)\n",
    "arb_df = df3.copy()\n",
    "arb_df['non-Cambridge uni'] = arb_df['school_1']\n",
    "arb_df['Cambridge?'] = 0\n",
    "\n",
    "arb_df = pd.concat([arb_df, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba12a32d",
   "metadata": {},
   "source": [
    "These two DataFrames, dup_df and arb_df, are used downstream for feature engineering and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3abc47",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5749e39f",
   "metadata": {},
   "source": [
    "### 4.1 Classifying based on university prestige\n",
    "\n",
    "I wanted to investigate the importance of going to a Russel group university affects admissions to Cambridge.\n",
    "\n",
    "To reflect the difference in prestige, I have grouped the universities of Oxford and Cambridge differently to other Russel group universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b41d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oxbridge =[\"University of Oxford\",\"University of Cambridge\"]\n",
    "Russel = [\n",
    "    \"University of Birmingham\",\n",
    "    \"University of Bristol\",\n",
    "    \"Cardiff University\",\n",
    "    \"Durham University\",\n",
    "    \"University of Edinburgh\",\n",
    "    \"University of Exeter\",\n",
    "    \"University of Glasgow\",\n",
    "    \"Imperial College London\",\n",
    "    \"King's College London\",\n",
    "    \"University of Leeds\",\n",
    "    \"University of Liverpool\",\n",
    "    \"The London School of Economics and Political Science (LSE)\",\n",
    "    \"University of Manchester\",\n",
    "    \"Newcastle University\",\n",
    "    \"University of Nottingham\",\n",
    "    \"University of Sheffield\",\n",
    "    \"University of Southampton\",\n",
    "    \"UCL\",\n",
    "    \"University of Warwick\",\n",
    "    \"University of York\",\n",
    "    \"Queen Mary University of London\",\n",
    "    \"Queen's University Belfast\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd0a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_uni(uni):\n",
    "    if uni in Russel:\n",
    "        return 1\n",
    "    elif uni in Oxbridge:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "dup_df[\"Uni Class\"] = dup_df[\"non-Cambridge uni\"].apply(classify_uni)\n",
    "arb_df[\"Uni Class\"]=arb_df[\"non-Cambridge uni\"].apply(classify_uni)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917b377",
   "metadata": {},
   "source": [
    "### 4.2 Including relevant experiences in leadership and data\n",
    "\n",
    "During data exploratory analysis, I found that data in the \"experiences\" feature is a list of dictionaries currently being stored as a string. To extract meaningful information, I have created fields capturing the months of experience in data related fields and leadership positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf1ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df['experiences'] = dup_df['experiences'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "arb_df['experiences']=arb_df['experiences'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84a3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_months(start, end):\n",
    "    \"\"\"Calculate the difference in months between two dates.\"\"\"\n",
    "    if end is None:\n",
    "        end = datetime.today().strftime('%Y-%m-%d') \n",
    "    start_date = datetime.strptime(start, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end, '%Y-%m-%d')\n",
    "    \n",
    "    return (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n",
    "\n",
    "\n",
    "def extract_experience(experiences):\n",
    "    data_months = 0\n",
    "    leader_months = 0\n",
    "\n",
    "    if isinstance(experiences, list):\n",
    "        for exp in experiences:\n",
    "            start = exp.get('start_date')\n",
    "            end = exp.get('end_date')\n",
    "            title = exp.get('title', '').lower()\n",
    "\n",
    "            if not start:\n",
    "                continue\n",
    "\n",
    "            months = calculate_months(start, end)\n",
    "\n",
    "            if any(word in title for word in ['data', 'analytics', 'ml', 'ai', 'scientist', 'engineer']):\n",
    "                data_months += months\n",
    "\n",
    "            if any(word in title for word in ['president', 'vice president', 'founder', 'head', 'CEO', 'COO']):\n",
    "                leader_months += months\n",
    "\n",
    "    return data_months,leader_months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f9ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df[['data_months', 'leader_months']] = dup_df['experiences'].apply(lambda x: pd.Series(extract_experience(x)))\n",
    "\n",
    "arb_df[['data_months', 'leader_months']] = arb_df['experiences'].apply(lambda x: pd.Series(extract_experience(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f043963",
   "metadata": {},
   "source": [
    "### 4.3 Exploring the effect of QS Rankings and handling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18dbe399",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs=pd.read_csv(r\"../datasets/qs-world-rankings-2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3fc063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df = dup_df.merge(qs[['Institution Name', '2025 Rank']], \n",
    "                         how='left', \n",
    "                         left_on='non-Cambridge uni', \n",
    "                         right_on='Institution Name')\n",
    "\n",
    "arb_df = arb_df.merge(qs[['Institution Name', '2025 Rank']], \n",
    "                         how='left', \n",
    "                         left_on='non-Cambridge uni', \n",
    "                         right_on='Institution Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a82c25",
   "metadata": {},
   "source": [
    "In this process, it was found that a number of records were falling out due to small differences in the university names. To handle these, I considered using a fuzzy match but chose against it since some of the values in \"non-Cambridge uni\" are that of sixth form colleges. To avoid incorrectly matching these, I chose to handle most fallouts by hand.\n",
    "\n",
    "While this was time inefficient, it gave me greater control over the quality of my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e72e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched = dup_df[dup_df['2025 Rank'].isna()]['non-Cambridge uni'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2548e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_overrides = {\n",
    "    \"University of Warwick\": 69,\n",
    "    \"University of Warwick - Warwick Business School\": 69,\n",
    "    \"Massachusetts Institute of Technology\": 1,\n",
    "    \"University of Sydney\": 18,\n",
    "    \"Indian Institute of Technology, Madras\": 227,\n",
    "    \"Trinity College Dublin\": 87,\n",
    "    \"Cardiff University / Prifysgol Caerdydd\": 186,\n",
    "    \"City St George’s, University of London\": 352,\n",
    "    \"Københavns Universitet - University of Copenhagen\": 100,\n",
    "    \"University of Exeter\": 169,\n",
    "    \"University of Naples ‘Parthenope’\": 1100,\n",
    "    \"Saïd Business School, University of Oxford\": 3,\n",
    "    \"University of Canterbury\": 261,\n",
    "    \"UC Santa Barbara\": 178,\n",
    "    \"Middlesex University (Hornsey College of Art)\": 725,\n",
    "    \"University of Hamburg\": 191,\n",
    "    \"Royal Holloway, University of London\": 477,\n",
    "    \"University of Benin\": 1350,\n",
    "    \"Vellore Institute of Technology\": 795,\n",
    "    \"Imperial College Business School\": 2,\n",
    "    \"Universidad Politécnica de Madrid\": 321,\n",
    "    \"Kingston University\": 605,\n",
    "    \"Univeristy of Cambridge\": 5,\n",
    "    \"Delhi University\": 328\n",
    "}\n",
    "\n",
    "\n",
    "def apply_rank_overrides(df):\n",
    "    df['2025 Rank'] = df.apply(\n",
    "        lambda row: rank_overrides.get(row['non-Cambridge uni'], row['2025 Rank']),\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "dup_df = apply_rank_overrides(dup_df)\n",
    "arb_df = apply_rank_overrides(arb_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6419f9",
   "metadata": {},
   "source": [
    "As my dataset is small, I chose to handle all other null values differently.\n",
    "\n",
    "On investigating the QS ranking dataset, I noticed that the dataset only included the top 1500 universities.\n",
    "\n",
    "Furthermore, I observed that after the first 600 universities the rankings are a range. To handle this, I decided to assign such records the average of the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3069970",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df[\"2025 Rank\"]=dup_df[\"2025 Rank\"].fillna(9999)\n",
    "arb_df[\"2025 Rank\"]=arb_df[\"2025 Rank\"].fillna(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0df02952",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df[\"2025 Rank\"]=dup_df[\"2025 Rank\"].astype(str)\n",
    "arb_df[\"2025 Rank\"]=arb_df[\"2025 Rank\"].astype(str)\n",
    "\n",
    "def convert_ranges(value):\n",
    "    if \"-\" in value:\n",
    "        lower, upper = map(int, value.split('-'))\n",
    "        return (lower + upper) // 2  \n",
    "    else:\n",
    "        return int(value)\n",
    "\n",
    "\n",
    "\n",
    "dup_df['2025 Rank'] = dup_df['2025 Rank'].apply(convert_ranges)\n",
    "arb_df['2025 Rank'] = arb_df['2025 Rank'].apply(convert_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be41f4",
   "metadata": {},
   "source": [
    "### 4.4 Fuzzy skill grouping and one-hot encoding selected skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fd3fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all unique skills from one dataset (repeat for both if needed)\n",
    "raw_skills = pd.concat([dup_df['top_skill_1'], dup_df['top_skill_2'], dup_df['top_skill_3']]).dropna().unique().tolist()\n",
    "\n",
    "# Build mapping via rapidfuzz\n",
    "skill_map = {}\n",
    "for s in raw_skills:\n",
    "    match, score, _ = process.extractOne(s, raw_skills, scorer=fuzz.WRatio)\n",
    "    skill_map[s] = match if score >= 80 else s\n",
    "\n",
    "# Apply mapping to create fuzzy columns\n",
    "def apply_fuzzy(df):\n",
    "    for col in ['top_skill_1','top_skill_2','top_skill_3']:\n",
    "        df[col + '_fuzzy'] = df[col].map(skill_map).fillna(df[col])\n",
    "    return df\n",
    "\n",
    "dup_df = apply_fuzzy(dup_df)\n",
    "arb_df = apply_fuzzy(arb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d43ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIG_SKILLS = [\"SQL\",\"Microsoft Excel\",\"Engineering\",\"Mathematical Modeling\",\n",
    "              \"Matlab\",\"Communication\",\"Data Science\",\"Physics\"]\n",
    "for df in [dup_df, arb_df]:\n",
    "    df['all_skills'] = df[['top_skill_1_fuzzy','top_skill_2_fuzzy','top_skill_3_fuzzy']].values.tolist()\n",
    "    for s in SIG_SKILLS:\n",
    "        col_name = f\"skill_{s.replace(' ', '_')}\"\n",
    "        df[col_name] = df['all_skills'].apply(lambda lst: int(s in lst))\n",
    "    df.drop(columns=['all_skills'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0484124b",
   "metadata": {},
   "source": [
    "## 5. Model Pipelines\n",
    "\n",
    "We start by picking relevant features and defining a helper to prepare X,y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b4a6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = [\"Uni Class\",\"data_months\",\"leader_months\",\"2025 Rank\"]\n",
    "SKILL_COLS = [f\"skill_{s.replace(' ','_')}\" for s in SIG_SKILLS]\n",
    "FEATURES = BASE + SKILL_COLS\n",
    "\n",
    "def prep(df):\n",
    "    X = df[FEATURES].astype(float)\n",
    "    y = df['Cambridge?']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176dfea",
   "metadata": {},
   "source": [
    "We will now define our models and parameter grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1db3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    'Logistic': (LogisticRegression(max_iter=1000, random_state=42), {'C':[0.1,1,10]}),\n",
    "    'RandomForest': (RandomForestClassifier(random_state=42), {'n_estimators':[100,200],'max_depth':[None,10]}),\n",
    "    'ExtraTrees': (ExtraTreesClassifier(random_state=42), {'n_estimators':[100,200],'max_depth':[None,10]}),\n",
    "    'XGBoost': (XGBClassifier(use_label_encoder=False,eval_metric='logloss',random_state=42), {'n_estimators':[100,200],'max_depth':[None,10]})\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d17077",
   "metadata": {},
   "source": [
    "We will now train and evaluate on all models on both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b40fb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anagh\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:17:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\anagh\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:17:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = 'results'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def run_all(df, ds_name):\n",
    "    X, y = prep(df)\n",
    "    ds_folder = os.path.join(OUTPUT_DIR, ds_name)\n",
    "    os.makedirs(ds_folder, exist_ok=True)\n",
    "    for model_name, (clf, grid) in MODELS.items():\n",
    "        pipe = Pipeline([('smote', SMOTE(random_state=42)), ('clf', clf)])\n",
    "        grid_params = {f'clf__{k}': v for k, v in grid.items()}\n",
    "        \n",
    "        Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        gs = GridSearchCV(pipe, grid_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "        gs.fit(Xtr, ytr)\n",
    "        preds = gs.predict(Xte)\n",
    "        out_path = os.path.join(ds_folder, f\"{model_name}.txt\")\n",
    "        with open(out_path, 'w') as f:\n",
    "            f.write(f\"Dataset: {ds_name}\\n\")\n",
    "            f.write(f\"Model: {model_name}\\n\")\n",
    "            f.write(f\"Best Params: {gs.best_params_}\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy_score(yte, preds):.4f}\\n\")\n",
    "            f.write(f\"ROC-AUC: {roc_auc_score(yte, preds):.4f}\\n\")\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            f.write(classification_report(yte, preds))\n",
    "            f.write(\"\\nConfusion Matrix:\\n\")\n",
    "            f.write(str(confusion_matrix(yte, preds)))\n",
    "\n",
    "\n",
    "\n",
    "def run_all_models():\n",
    "    run_all(dup_df, 'duplication')\n",
    "    run_all(arb_df, 'arbitrary')\n",
    "\n",
    "\n",
    "run_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "719e2743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anagh\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:17:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\anagh\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:17:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for ds_name, df_ in [('dup_df', dup_df), ('arb_df', arb_df)]:\n",
    "    X_full, y_full = prep(df_)\n",
    "    clf = MODELS['XGBoost'][0]\n",
    "    pipe = Pipeline([('smote', SMOTE(random_state=42)), ('clf', clf)])\n",
    "    pipe.fit(X_full, y_full)\n",
    "\n",
    "    explainer = shap.TreeExplainer(pipe.named_steps['clf'])\n",
    "    shap_values = explainer.shap_values(X_full)\n",
    "\n",
    "    shap_dir = os.path.join('results', 'shap', ds_name)\n",
    "    os.makedirs(shap_dir, exist_ok=True)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    shap.summary_plot(shap_values, X_full, feature_names=FEATURES, show=False)\n",
    "    fig.savefig(os.path.join(shap_dir, 'xgboost_summary.png'), bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b6502",
   "metadata": {},
   "source": [
    "To conclude, here are the **three key insights** from my analysis:\n",
    "\n",
    "1. **University Prestige is the Strongest Predictor**  \n",
    "   Prior attendance at an Oxbridge or Russell Group institution (captured by `Uni Class` and QS `2025 Rank`) consistently had the highest feature importance and SHAP values, underscoring the role of institutional pedigree in Cambridge admissions predictions.\n",
    "\n",
    "2. **Technical Skills Provide Nuanced Signals**  \n",
    "   Of the validated skills, **SQL**, **Microsoft Excel**, and **Physics** emerged as meaningful predictors—sometimes correlating negatively—highlighting that even strong technical proficiencies may not uniformly increase admission probability and may interact with other factors.\n",
    "\n",
    "3. **Leadership Experience Reflects Career Stage Bias**  \n",
    "   Surprisingly, greater months in leadership roles tended to negatively influence predicted admission likelihood. A plausible interpretation is that candidates further along in their careers (with longer leadership tenures) are less likely to pursue full-time postgraduate study, illuminating a career trajectory effect.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
